{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRICE HISTORY SCRIPT\n",
    "# This script is responsible for getting the price\n",
    "# history of any symbol passed to the constructor\n",
    "from src.urls import TDA_BASE\n",
    "from config.secrets import TDA_APIKEY, PERIOD, PERIODTYPE, FREQUENCY, FREQUENCYTYPE\n",
    "import requests\n",
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from models.mysql_db import create_pricehistory_engine, generate_symbols, _select_symbols\n",
    "from loguru import logger\n",
    "import os.path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE THE LOGGER FOR THIS SCRIPT:\n",
    "log_path = str(os.path.curdir) + '/logs/'\n",
    "base_fmt = \"[{time:YYYY-MM-DD at HH:mm:ss}]|[{name}]-[<lvl>{message}</lvl>]\"\n",
    "logger.add(log_path+\"pricehistory.log\", format=base_fmt, level=\"DEBUG\", rotation=\"20 MB\",\n",
    "           colorize=True, enqueue=True, catch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n=================================================================================\\nTHE PRICE HISTORY CLASS|\\n-----------------------+\\nThis will be responsible for getting the price history for every symbol\\nstored in the database. Using a generator function in the models.mysql_db\\nscript, I will be able to generate one symbol at a time and then execute\\nthe insert_price_data() method.\\n\\nI am going to try two different approaches. First, I will try the map()\\nfunction to see if it can handle executing the function on that long of\\na list.\\n\\nIf that doesn't work, I will try to utilize the generator function to\\ngenerate one symbol at a time and only execute the insert method one\\nstock at a time.\\n=================================================================================\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "=================================================================================\n",
    "THE PRICE HISTORY CLASS|\n",
    "-----------------------+\n",
    "This will be responsible for getting the price history for every symbol\n",
    "stored in the database. Using a generator function in the models.mysql_db\n",
    "script, I will be able to generate one symbol at a time and then execute\n",
    "the insert_price_data() method.\n",
    "\n",
    "I am going to try two different approaches. First, I will try the map()\n",
    "function to see if it can handle executing the function on that long of\n",
    "a list.\n",
    "\n",
    "If that doesn't work, I will try to utilize the generator function to\n",
    "generate one symbol at a time and only execute the insert method one\n",
    "stock at a time.\n",
    "=================================================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessPricehistory(ProcessPoolExecutor):\n",
    "\n",
    "    def __init__(self, task, workers: int):\n",
    "        super(ProcessPricehistory, self).__init__()\n",
    "        self.task = task\n",
    "        self.executor = ProcessPoolExecutor(max_workers=workers)\n",
    "\n",
    "    def run(self):\n",
    "        # THIS WILL EXECUTE THE MAIN METHOD IN QUOTE USING MAP AND THREADED POOL PROCESSES:\n",
    "        logger.info(\n",
    "            \"Running Process Pool Executor on Pricehistory's execute_main method\")\n",
    "        self.executor.submit(self.task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceHistory:\n",
    "\n",
    "    def __init__(self, stocks:list, **params):\n",
    "        self.params = params  # params are set at bottom, imported from config.ini file\n",
    "        self.table_name = self._set_table_name()\n",
    "        self.stock_chunks = self.chunks(stocks)\n",
    "        \n",
    "        \n",
    "    def chunks(self, l: list, n: int = 200):\n",
    "        \"\"\"\n",
    "        :param l: takes in a list\n",
    "        :param n: Lets you know how long you want each chunk to be\n",
    "        \"\"\"\n",
    "        n = max(1, n)\n",
    "        logger.info(\"[+] Stocks chunked into groups of 200..\")\n",
    "        return (l[i: i + n] for i in range(0, len(l), n))\n",
    "\n",
    "    def _set_table_name(self):\n",
    "        \"\"\"\n",
    "        Simple way to set the name of the table to save the price data to\n",
    "        dynamically. This way no matter what the params are, the data will\n",
    "        be saved to correct table.\n",
    "        \"\"\"\n",
    "        if int(FREQUENCY) > 1:\n",
    "            name = f\"_{FREQUENCY}_{FREQUENCYTYPE}_data\"\n",
    "            logger.info(\"[+] Storing Pricehistory data to table: {}\", name)\n",
    "            return name\n",
    "        else:\n",
    "            name = f\"one_{FREQUENCYTYPE}_data\"\n",
    "            logger.info(\"[+] Storing Pricehistory data to table: {}\", name)\n",
    "            return name\n",
    "\n",
    "    def data(self, stock):\n",
    "        \"\"\"\n",
    "        :param symbol: company symbol/ticker\n",
    "        :Example: MSFT 10 day minute 10\n",
    "\n",
    "        :returns:\n",
    "        raw json data (Open, High, Low, close, Volume, and Time (epoch time))\n",
    "        \"\"\"\n",
    "        url = TDA_BASE + f\"marketdata/{stock}/pricehistory\"\n",
    "\n",
    "        params = {\n",
    "            'period': self.params['params']['period'],\n",
    "            'periodType': self.params['params']['periodType'],\n",
    "            'frequency': self.params['params']['frequency'],\n",
    "            'frequencyType': self.params['params']['frequencyType'],\n",
    "        }\n",
    "\n",
    "        # Other users will need their own TD Ameritrade API Key\n",
    "        params.update({\"apikey\": TDA_APIKEY})\n",
    "\n",
    "        # request price history data\n",
    "        req = requests.get(url, params=params).json()\n",
    "\n",
    "        candles = dict(req)  # turn candles into a dict() type\n",
    "        extracted_candles_list = candles[\"candles\"]\n",
    "        symbol = candles[\"symbol\"]  # symbol of the compan's price data\n",
    "\n",
    "        # Create data frame from extracted data\n",
    "        df = pd.DataFrame.from_dict(extracted_candles_list, orient=\"columns\")\n",
    "        df.rename(columns={\"datetime\": \"unix\"}, inplace=True)\n",
    "        df[\"unix\"] = [x for x in df[\"unix\"] // 10 ** 3]\n",
    "\n",
    "        # This is to insert the companies symbol into the data frame\n",
    "        # in every row next to the unix_time so that I can identify\n",
    "        # who the data belongs to.\n",
    "        df[\"symbol\"] = symbol\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def insert_price_data(self, data):\n",
    "        try:\n",
    "            table = self.table_name\n",
    "            engine = create_pricehistory_engine()\n",
    "            data.to_sql(name=table, con=engine,\n",
    "                        if_exists='append', index=False)\n",
    "            logger.info(\"{} inserted successfully!\", data[\"symbol\"][1])\n",
    "        except Exception as e:\n",
    "            logger.error(\"Error Caused Due to {}\", e)\n",
    "            \n",
    "    def execute_data(self, symbols):\n",
    "        # pool = multiprocessing.Pool(processes=4)\n",
    "        try:\n",
    "            logger.info(\"Multiprocessing Pool Starting to get price data\")\n",
    "            data = pd.concat([self.data(each)\n",
    "                                           for each in self.stock_chunks])\n",
    "            logger.info(\"Data Retrieved from ProcessPoolExecutor map method\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logger.error(\"Exception Raised: {}\", e)\n",
    "\n",
    "    def execute_main(self):\n",
    "        symbols = _select_symbols()\n",
    "        # symbol = generate_symbols()\n",
    "        # pool = multiprocessing.Pool(processes=4)\n",
    "        try:\n",
    "            count = 0\n",
    "            while True:\n",
    "                try:\n",
    "                    # stock = next(symbol)\n",
    "                    # self.insert_price_data(stock)\n",
    "                    # logger.info(\"[{}]<green>Price History Data Inserted Successfully</green>\", stock)\n",
    "                    logger.info(\"[<green>Price History Map Function Started</green>]\")\n",
    "                    map(self.insert_price_data, symbols)\n",
    "                    count += 1\n",
    "                except KeyError as ke:\n",
    "                    logger.error(\"Failed to insert: Due to {}\", ke)\n",
    "                    continue\n",
    "                except StopIteration as si:\n",
    "                    logger.info(\"{} No More Stocks to Get Data for\", si)\n",
    "                    continue\n",
    "        except ValueError as ve:\n",
    "            logger.error(\"Error Caused Due to {}\", ve)\n",
    "            if ve:\n",
    "                engine = self.pricehistory_engine\n",
    "                stmt = \"DROP TABLE IF EXISTS {table}\".format(self.table_name)\n",
    "                engine.execute(stmt)\n",
    "                logger.info(\"SQL Statement {} Executed...\", stmt)\n",
    "        except Exception as e:\n",
    "            logger.error(\"Error Caused Due to {}\", e)\n",
    "        finally:\n",
    "            logger.info(\"[{}] Stocks Inserted Successfully!\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = _select_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'symbol': 'stock',\n",
    "    'period': PERIOD,\n",
    "    'periodType': PERIODTYPE,\n",
    "    'frequency': FREQUENCY,\n",
    "    'frequencyType': FREQUENCYTYPE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 17:06:33.457 | INFO     | __main__:_set_table_name:30 - [+] Storing Pricehistory data to table: one_minute_data\n",
      "2022-05-15 17:06:33.458 | INFO     | __main__:chunks:15 - [+] Stocks chunked into groups of 200..\n",
      "2022-05-15 17:06:33.459 | INFO     | __main__:<cell line: 2>:2 - PriceHistory Object Initialized: Table one_minute_data created\n"
     ]
    }
   ],
   "source": [
    "price_history = PriceHistory(symbols, params=params)\n",
    "logger.info(\n",
    "    \"PriceHistory Object Initialized: Table {} created\", price_history.table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 13:51:15.371 | INFO     | __main__:execute_data:74 - Multiprocessing Pool Starting to get price data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "price_history.execute_main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = price_history.stock_chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'AA', 'AAC', 'AAI', 'AAIN', 'AAM', 'AAN', 'AAP', 'AAQ', 'AAQC', 'AAT', 'AB', 'ABB', 'ABBV', 'ABC', 'ABEV', 'ABG', 'ABM', 'ABR', 'ABT', 'AC', 'ACA', 'ACAQ', 'ACC', 'ACCO', 'ACD', 'ACDI', 'ACEL', 'ACH', 'ACHR', 'ACI', 'ACII', 'ACM', 'ACN', 'ACP', 'ACR', 'ACRE', 'ACRO', 'ACV', 'ADC', 'ADCT', 'ADE', 'ADEX', 'ADM', 'ADNT', 'ADT', 'ADX', 'AEE', 'AEFC', 'AEG', 'AEL', 'AEM', 'AENZ', 'AEO', 'AER', 'AES', 'AESC', 'AEV', 'AEVA', 'AFB', 'AFG', 'AFGB', 'AFGE', 'AFI', 'AFL', 'AFT', 'AFTR', 'AG', 'AGA', 'AGAC', 'AGCB', 'AGCO', 'AGD', 'AGI', 'AGL', 'AGM', 'AGO', 'AGR', 'AGRO', 'AGS', 'AGTI', 'AGX', 'AHH', 'AHL', 'AHT', 'AI', 'AIC', 'AIF', 'AIG', 'AIN', 'AIO', 'AIR', 'AIRC', 'AIT', 'AIU', 'AIV', 'AIZ', 'AIZN', 'AJG', 'AJRD', 'AJX', 'AJXA', 'AKA', 'AKO', 'AKR', 'AL', 'ALB', 'ALC', 'ALCC', 'ALE', 'ALEX', 'ALG', 'ALI', 'ALIT', 'ALK', 'ALL', 'ALLE', 'ALLG', 'ALLY', 'ALP', 'ALSN', 'ALT', 'ALV', 'ALX', 'AM', 'AMAM', 'AMB', 'AMBC', 'AMBP', 'AMC', 'AMCR', 'AME', 'AMG', 'AMH', 'AMK', 'AMN', 'AMOV', 'AMP', 'AMPI', 'AMPS', 'AMPY', 'AMR', 'AMRC', 'AMRX', 'AMT', 'AMTD', 'AMWL', 'AMX', 'AN', 'ANA', 'ANAC', 'ANET', 'ANF', 'ANTM', 'ANVS', 'AOD', 'AOMR', 'AON', 'AORT', 'AOS', 'AP', 'APAM', 'APC', 'APCA', 'APD', 'APG', 'APGB', 'APH', 'APLE', 'APN', 'APO', 'APRN', 'APS', 'APSG', 'APT', 'APTS', 'APTV', 'AQN', 'AQNA', 'AQNB', 'AQUA', 'AR', 'ARC', 'ARCH', 'ARCO', 'ARDC', 'ARE', 'ARES', 'ARG', 'ARGD', 'ARGO', 'ARI', 'ARIS', 'ARL', 'ARLO', 'ARMK', 'ARNC', 'AROC', 'ARR', 'ARW']\n"
     ]
    }
   ],
   "source": [
    "print(next(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = map(price_history.data, symbols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'unix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\charl\\Envs\\mlenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\charl\\Envs\\mlenv\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\charl\\Envs\\mlenv\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'unix'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\charl\\OneDrive\\dev\\source\\finlearn\\notebook.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/charl/OneDrive/dev/source/finlearn/notebook.ipynb#ch0000014?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m d:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/charl/OneDrive/dev/source/finlearn/notebook.ipynb#ch0000014?line=1'>2</a>\u001b[0m     df\u001b[39m.\u001b[39mappend(i)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/charl/OneDrive/dev/source/finlearn/notebook.ipynb#ch0000014?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(i)\n",
      "\u001b[1;32mc:\\Users\\charl\\OneDrive\\dev\\source\\finlearn\\notebook.ipynb Cell 5'\u001b[0m in \u001b[0;36mPriceHistory.data\u001b[1;34m(self, stock)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/charl/OneDrive/dev/source/finlearn/notebook.ipynb#ch0000004?line=60'>61</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(extracted_candles_list, orient\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/charl/OneDrive/dev/source/finlearn/notebook.ipynb#ch0000004?line=61'>62</a>\u001b[0m df\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39munix\u001b[39m\u001b[39m\"\u001b[39m}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/charl/OneDrive/dev/source/finlearn/notebook.ipynb#ch0000004?line=62'>63</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39munix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m df[\u001b[39m\"\u001b[39;49m\u001b[39munix\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m10\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m3\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/charl/OneDrive/dev/source/finlearn/notebook.ipynb#ch0000004?line=64'>65</a>\u001b[0m \u001b[39m# This is to insert the companies symbol into the data frame\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/charl/OneDrive/dev/source/finlearn/notebook.ipynb#ch0000004?line=65'>66</a>\u001b[0m \u001b[39m# in every row next to the unix_time so that I can identify\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/charl/OneDrive/dev/source/finlearn/notebook.ipynb#ch0000004?line=66'>67</a>\u001b[0m \u001b[39m# who the data belongs to.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/charl/OneDrive/dev/source/finlearn/notebook.ipynb#ch0000004?line=67'>68</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39msymbol\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m symbol\n",
      "File \u001b[1;32mc:\\Users\\charl\\Envs\\mlenv\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/frame.py?line=3502'>3503</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/frame.py?line=3503'>3504</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/frame.py?line=3504'>3505</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/frame.py?line=3505'>3506</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/frame.py?line=3506'>3507</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\charl\\Envs\\mlenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/charl/Envs/mlenv/lib/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'unix'"
     ]
    }
   ],
   "source": [
    "for i in d:\n",
    "    df.append(i)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "740257c0656e5e215c694fcc67c8babcc423680e95ff929c26f641ec481bbb57"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
